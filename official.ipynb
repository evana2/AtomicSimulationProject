{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "official.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFTLYpawY9WH"
      },
      "source": [
        "###step 0: imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "from pandas_datareader import data as pdr\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import plotting\n",
        "###step 2: load in variables\n",
        "#lists of stocks\n",
        "bottomstocksList = ['LEG' , 'RL' , 'HBI' , 'IPGP', 'FOX', 'GPS' , 'UAA', 'DISCA' , 'UA' , 'NWS']\n",
        "#1)Leggett & Platt 2) Ralph Lauren Corporation 3) Hanesbrands Inc. 4) IPG Photonics Corporation 5)Fox Corporation\n",
        "#6)The Gap, Inc. 7)Under Armour, Inc. 8)Discovery, Inc. 9) Under Armour, Inc. 10) News Corporation\n",
        "\n",
        "topstocksList = ['AAPL', 'MSFT' , 'AMZN' , 'TSLA' , 'GOOGL', 'FB', 'NVDA', 'BRK-B', 'JPM' , 'JNJ']\n",
        "#1)Apple Inc.  2) 3) 4) 5)\n",
        "#6) 7) 8) 9) 10)\n",
        "\n",
        "cryptoList = ['ADA', 'SOL1' , 'DOT1' , 'MIOTA', 'EOS' , 'XLM', 'AVAX', 'ATOM1', 'ALGO', 'SHIB']\n",
        "#\n",
        "cryptos = [crypto + '-USD' for crypto in cryptoList]\n",
        "\n",
        "commodities = ['CL=F', 'NG=F', 'GC=F', 'SI=F','LE=F', 'ZC=F', 'KC=F', 'SB=F', 'HG=F', 'ZW=F'] \n",
        "#1)crude oil 2)natural gas 3)gold 4)silver 5)live cattle 6)corn 7)coffee  8)sugar 9)copper 10) wheat\n",
        "\n",
        "#date range of past year\n",
        "endDate = dt.datetime(2021, 11, 18)\n",
        "startDate = endDate - dt.timedelta(days=365)\n",
        "\n",
        "#groups of interest\n",
        "group_top = topstocksList\n",
        "group_bttm = bottomstocksList\n",
        "group_top_commd = topstocksList+commodities\n",
        "group_bttm_commd = bottomstocksList+commodities\n",
        "group_top_crypt = topstocksList+cryptos\n",
        "group_bttm_crypt = bottomstocksList+cryptos\n",
        "\n",
        "groups = [group_bttm, group_bttm_commd, group_bttm_crypt, group_top, group_top_commd, group_top_crypt]\n",
        "group_name = [\"Bottom Stocks\", \"Bottom Stocks & Commodities\", \"Bottom Stocks & Crypts\", \"Top Stocks\", \"Top Stocks & Commodities\", \"Top Stocks & Cryptos\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIUj2amjYnVq"
      },
      "source": [
        "###step 2: load in functions\n",
        "\n",
        "#function to pull stock data from yahoo finance\n",
        "#given a list of stocks returns their mean returns, covariance and correlation\n",
        "def get_data(stocks, start, end):\n",
        "    stockData = pdr.DataReader(stocks, 'yahoo', start, end)\n",
        "    stockData = stockData['Close']\n",
        "    returns = stockData.pct_change()\n",
        "    meanReturns = returns.mean()\n",
        "    covMatrix = returns.cov()\n",
        "    corMatrix = returns.corr()\n",
        "    return meanReturns, covMatrix, corMatrix\n",
        "\n",
        "#load a set of data\n",
        "def load_data(group_idx = 0):\n",
        "  meanReturns, covMatrix, corMatrix = get_data(groups[group_idx], startDate, endDate)\n",
        "  return meanReturns, covMatrix, corMatrix\n",
        "\n",
        "#calculates optimal weights and plots their distribution\n",
        "def get_optimal_weights(group_idx, meanReturns, covMatrix):\n",
        "  ef = EfficientFrontier(meanReturns*180, covMatrix*180)\n",
        "  weights = ef.max_sharpe()\n",
        "  cleaned_weights = ef.clean_weights()\n",
        "  cleaned_weights =  list(cleaned_weights.items())\n",
        "  cleaned_weights = [y for (x,y) in cleaned_weights]\n",
        "\n",
        "  #plot weight distribution\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_axes([0,0,1,1])\n",
        "  ax.bar(groups[group_idx], cleaned_weights, color=['blue']*10+['green']*10)\n",
        "  plt.xticks(rotation = 45) # Rotates X-Axis Ticks by 45-degrees\n",
        "\n",
        "  title_string = \"Optimal Weight Distribution (\" + group_name[group_idx] + \")\"\n",
        "  plt.title(title_string)\n",
        "  file_name = title_string + \".png\"\n",
        "  #plt.savefig(file_name)\n",
        "  plt.savefig(file_name,bbox_inches='tight', dpi=150)\n",
        "  return cleaned_weights\n",
        "\n",
        "#graphs efficient frontier plot\n",
        "def graph_efficiency_frontier(group_idx, meanReturns, covMatrix):\n",
        "  ef = EfficientFrontier(meanReturns*180, covMatrix*180, solver=\"SCS\")\n",
        "  fig, ax = plt.subplots()\n",
        "  plotting.plot_efficient_frontier(ef, ax=ax, show_assets=False)\n",
        "\n",
        "  # Find the tangency portfolio\n",
        "  ef = EfficientFrontier(meanReturns*180, covMatrix*180)\n",
        "  ef.max_sharpe()\n",
        "  ret_tangent, std_tangent, _ = ef.portfolio_performance()\n",
        "  ax.scatter(std_tangent, ret_tangent, marker=\"*\", s=100, c=\"r\", label=\"Max Sharpe\")\n",
        "\n",
        "  #run a monte carlo simulation of portfolio weights\n",
        "  n_samples = 1000\n",
        "  w = np.random.dirichlet(np.ones(len(meanReturns)), n_samples)\n",
        "  rets = w.dot(meanReturns*180)\n",
        "  stds = np.sqrt(np.diag(w @ covMatrix*180 @ w.T))\n",
        "  sharpes = rets / stds\n",
        "  ax.scatter(stds, rets, marker=\".\", c=sharpes, cmap=\"RdYlGn\")\n",
        "\n",
        "  #mark lowest volatility with blue diamond\n",
        "  min_std_i = np.argmin(stds)\n",
        "  plt.scatter(stds[min_std_i],rets[min_std_i],marker=\"D\",color='b',s=80, label='Lowest Volatility')\n",
        "  #mark max sharpe ratio with red diamond\n",
        "  max_sha_i = np.argmax(sharpes)\n",
        "  plt.scatter(stds[max_sha_i],rets[max_sha_i],marker=\"D\",color='r',s=80, label='Best Sharpe Ratio')\n",
        "  #mark equal distribution with green diamond\n",
        "  equal_weights = np.ones(len(meanReturns)) / len(meanReturns)\n",
        "  eq_return = (meanReturns*180)@equal_weights\n",
        "  eq_std_dev = np.sqrt(equal_weights@(covMatrix*180)@equal_weights)\n",
        "  plt.scatter(eq_std_dev, eq_return, marker=\"D\", color='g', s=80, label='Equal Distribution')\n",
        "\n",
        "  #add legend\n",
        "  plt.legend(loc=4)\n",
        "\n",
        "  #title and save graph\n",
        "  title_string = \"Efficient Frontier with random Portfolios (\" + group_name[group_idx] + \")\"\n",
        "  plt.title(title_string)\n",
        "  file_name = title_string + \".png\"\n",
        "  plt.savefig(file_name, bbox_inches = 'tight')\n",
        "  plt.cla()\n",
        "  plt.clf()\n",
        "def get_GHHI(weights, corMatrix):\n",
        "  #GHHI diversity (uses weights and correlation matrix)\n",
        "  num_items = len(weights)\n",
        "  HHI = 0\n",
        "  GHHI = 0\n",
        "  for i in range(num_items):\n",
        "      HHI += (weights[i] ** 2)\n",
        "      for j in range(num_items):\n",
        "          if (i == j):\n",
        "            continue\n",
        "          GHHI += weights[i] * weights[j] * 2\n",
        "          corMatrix.iat[i,j]\n",
        "  return (GHHI+HHI)\n",
        "\n",
        "def get_projected_Sharpe(weights, meanReturns, covMatrix):\n",
        "  #projected sharpe ratio\n",
        "  portfolio_return =  np.sum(meanReturns*weights)*180\n",
        "  portfolio_std_dev = np.sqrt(weights@(covMatrix)@weights)*np.sqrt(180)\n",
        "  s = (portfolio_return - 0) / portfolio_std_dev\n",
        "  return s\n",
        "\n",
        "def run_Monte_Carlo(group_idx, weights, meanReturns, covMatrix):\n",
        "  # Monte Carlo Simulation of Price\n",
        "  mc_sims = 4000 # number of simulations\n",
        "  T = 180 #timeframe in days\n",
        "\n",
        "  meanM = np.full(shape=(T, len(weights)), fill_value=meanReturns)\n",
        "  meanM = meanM.T\n",
        "\n",
        "  portfolio_sims = np.full(shape=(T, mc_sims), fill_value=0.0)\n",
        "\n",
        "  initialPortfolio = 10000 #value (dollars)\n",
        "\n",
        "  for m in range(0, mc_sims):\n",
        "      Z = np.random.normal(size=(T, len(weights)))#uncorrelated RV's\n",
        "      L = np.linalg.cholesky(covMatrix) #Cholesky decomposition to Lower Triangular Matrix\n",
        "      dailyReturns = meanM + np.inner(L, Z) #Correlated daily returns for individual stocks\n",
        "      portfolio_sims[:,m] = np.cumprod(np.inner(weights, dailyReturns.T)+1)*initialPortfolio\n",
        "\n",
        "  plt.plot(portfolio_sims)\n",
        "  plt.ylabel('Portfolio Value ($)')\n",
        "  plt.xlabel('Days')\n",
        "  title_string = \"MC Portfolio Simulation (\" + group_name[group_idx] + \")\"\n",
        "  plt.title(title_string)\n",
        "  file_name = title_string + \".png\"\n",
        "  plt.savefig(file_name,  bbox_inches = 'tight')\n",
        "\n",
        "  #calculate values to return\n",
        "  #returns (uses total on last day and initialPortfolio value)\n",
        "  total_returns = np.zeros(mc_sims)\n",
        "  for i in range(mc_sims):\n",
        "      total_returns[i] = (portfolio_sims[-1,i] - initialPortfolio) / initialPortfolio\n",
        "\n",
        "  #risk (uses returns, and standard deviation)\\\n",
        "  risk_free = 0\n",
        "  sharpe_ratio = (total_returns.mean() - risk_free) / total_returns.std()\n",
        "\n",
        "  return total_returns.mean(), total_returns.std(), sharpe_ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBHUeiW1bnla"
      },
      "source": [
        "#run full simulation for all groups\n",
        "for i in range(len(groups)):\n",
        "  meanReturns, covMatrix, corMatrix = load_data(i)\n",
        "\n",
        "  optimal_weights = get_optimal_weights(i, meanReturns, covMatrix)\n",
        "\n",
        "  graph_efficiency_frontier(i, meanReturns, covMatrix)\n",
        "\n",
        "  GHHI = get_GHHI(optimal_weights, corMatrix)\n",
        "  \n",
        "  projected_sharpe_ratio = get_projected_Sharpe(optimal_weights, meanReturns, covMatrix)\n",
        "\n",
        "  mean_returns, volatility, sharpe_ratio = run_Monte_Carlo(i, optimal_weights, meanReturns, covMatrix)\n",
        "\n",
        "  with open('results.txt', 'a') as f:\n",
        "      f.write('\\n\\nData for ')\n",
        "      f.write(group_name[i])\n",
        "      f.write('\\nOptimal Weights: [')\n",
        "      for w in optimal_weights:\n",
        "        f.write(\"%s,\" % w)\n",
        "      f.write(f\"]\\nGHHI: {GHHI}\\n\")\n",
        "      f.write(f\"Projected Sharpe Ratio: {projected_sharpe_ratio}\\n\")\n",
        "      f.write(f\"Monte Carlo Results \\nReturns: {mean_returns} Volatility: {volatility} Sharpe ratio: {sharpe_ratio}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
